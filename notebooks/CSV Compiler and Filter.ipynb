{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "76ddd320",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "def get_filenames(mypath):\n",
    "    return [f for f in listdir(mypath) if isfile(join(mypath, f))]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ef58b9a",
   "metadata": {},
   "source": [
    "Convert the TFRecord files for the training set into a CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1790dcdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done making the array. Converting to Pandas DF and saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>time_stamp</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>...</th>\n",
       "      <th>118</th>\n",
       "      <th>119</th>\n",
       "      <th>120</th>\n",
       "      <th>121</th>\n",
       "      <th>122</th>\n",
       "      <th>123</th>\n",
       "      <th>124</th>\n",
       "      <th>125</th>\n",
       "      <th>126</th>\n",
       "      <th>127</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>--cB2ZVjpnA</td>\n",
       "      <td>30.0</td>\n",
       "      <td>95</td>\n",
       "      <td>122</td>\n",
       "      <td>147</td>\n",
       "      <td>14</td>\n",
       "      <td>101</td>\n",
       "      <td>48</td>\n",
       "      <td>157</td>\n",
       "      <td>125</td>\n",
       "      <td>...</td>\n",
       "      <td>185</td>\n",
       "      <td>0</td>\n",
       "      <td>186</td>\n",
       "      <td>0</td>\n",
       "      <td>63</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>2</td>\n",
       "      <td>190</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>--cB2ZVjpnA</td>\n",
       "      <td>30.96</td>\n",
       "      <td>123</td>\n",
       "      <td>109</td>\n",
       "      <td>137</td>\n",
       "      <td>33</td>\n",
       "      <td>145</td>\n",
       "      <td>126</td>\n",
       "      <td>43</td>\n",
       "      <td>90</td>\n",
       "      <td>...</td>\n",
       "      <td>56</td>\n",
       "      <td>157</td>\n",
       "      <td>92</td>\n",
       "      <td>139</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>84</td>\n",
       "      <td>123</td>\n",
       "      <td>140</td>\n",
       "      <td>248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>--cB2ZVjpnA</td>\n",
       "      <td>31.92</td>\n",
       "      <td>52</td>\n",
       "      <td>135</td>\n",
       "      <td>152</td>\n",
       "      <td>7</td>\n",
       "      <td>62</td>\n",
       "      <td>112</td>\n",
       "      <td>121</td>\n",
       "      <td>83</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>129</td>\n",
       "      <td>35</td>\n",
       "      <td>238</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>0</td>\n",
       "      <td>255</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>--cB2ZVjpnA</td>\n",
       "      <td>32.88</td>\n",
       "      <td>53</td>\n",
       "      <td>167</td>\n",
       "      <td>104</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>147</td>\n",
       "      <td>174</td>\n",
       "      <td>62</td>\n",
       "      <td>...</td>\n",
       "      <td>136</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>202</td>\n",
       "      <td>90</td>\n",
       "      <td>66</td>\n",
       "      <td>255</td>\n",
       "      <td>241</td>\n",
       "      <td>255</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>--cB2ZVjpnA</td>\n",
       "      <td>33.84</td>\n",
       "      <td>26</td>\n",
       "      <td>220</td>\n",
       "      <td>90</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>98</td>\n",
       "      <td>66</td>\n",
       "      <td>34</td>\n",
       "      <td>...</td>\n",
       "      <td>255</td>\n",
       "      <td>0</td>\n",
       "      <td>178</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>180</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 130 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      video_id time_stamp    0    1    2   3    4    5    6    7  ...  118  \\\n",
       "0  --cB2ZVjpnA       30.0   95  122  147  14  101   48  157  125  ...  185   \n",
       "1  --cB2ZVjpnA      30.96  123  109  137  33  145  126   43   90  ...   56   \n",
       "2  --cB2ZVjpnA      31.92   52  135  152   7   62  112  121   83  ...    0   \n",
       "3  --cB2ZVjpnA      32.88   53  167  104   0   50  147  174   62  ...  136   \n",
       "4  --cB2ZVjpnA      33.84   26  220   90  17    0   98   66   34  ...  255   \n",
       "\n",
       "   119  120  121  122  123  124  125  126  127  \n",
       "0    0  186    0   63  255  255    2  190    0  \n",
       "1  157   92  139    0   26   84  123  140  248  \n",
       "2    0  129   35  238  255  255    0  255    0  \n",
       "3    0    0  202   90   66  255  241  255    0  \n",
       "4    0  178    0   22  255  255  255  180    0  \n",
       "\n",
       "[5 rows x 130 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filenames = [\"../data/audioset_v1_embeddings/bal_train/\" + i for i in get_filenames(\"../data/audioset_v1_embeddings/bal_train/\")]\n",
    "train_dataset = tf.data.TFRecordDataset(filenames)\n",
    "\n",
    "# Make Pandas DataFrame out of the training set records.\n",
    "col = ['video_id', 'time_stamp'] + [str(k) for k in range(0,128)]\n",
    "\n",
    "placeholder_array = np.array(col)\n",
    "\n",
    "for raw_record in train_dataset:\n",
    "    example = tf.train.SequenceExample()\n",
    "    example.ParseFromString(raw_record.numpy())\n",
    "    for i in range(0,len(example.feature_lists.feature_list['audio_embedding'].feature)):\n",
    "        vID = example.context.feature['video_id'].bytes_list.value[0]\n",
    "        time = example.context.feature['start_time_seconds'].float_list.value[0] + 0.96*i\n",
    "        placeholder_array = np.vstack((placeholder_array, np.array([vID, time] + list(example.feature_lists.feature_list['audio_embedding'].feature[i].bytes_list.value[0]))))\n",
    "\n",
    "print('Done making the array. Converting to Pandas DF and saving.')\n",
    "\n",
    "trainFeatures = pd.DataFrame(np.delete(placeholder_array, 0, 0), columns = col)\n",
    "\n",
    "trainFeatures.to_csv('trainFeatures.csv')\n",
    "trainFeatures.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ec0716e",
   "metadata": {},
   "source": [
    "Prepare the targets CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8827dd5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally, make a Pandas DF for the target: whether or not speech is present in each 0.96 second chunk.\n",
    "trainTargets = pd.read_csv('trainFeatures.csv', header = 0, index_col = 0).iloc[:,0:2]\n",
    "trainTargets['speech_present'] = False # By default.\n",
    "\n",
    "# Make a Pandas DataFrame of all instances of speech present.\n",
    "trainEvents = pd.read_csv(\"../data/audioset_train_strong.tsv\", sep=\"\\t\")\n",
    "\n",
    "''' Have to make the labels match the feature set,\n",
    "    and these labels have a \"_\" followed by trailing digits.'''\n",
    "trainEvents.iloc[:,0] = trainEvents.iloc[:,0].str.rstrip(\"0123456789\")\n",
    "trainEvents.iloc[:,0] = trainEvents.iloc[:,0].str.rstrip(\"_\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "118629c0",
   "metadata": {},
   "source": [
    "Take the intersection of the feature set and the subset with strong temporal labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc15ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "filter = set(trainTargets.iloc[:,0]).intersection(set(trainEvents.iloc[:,0]))\n",
    "\n",
    "for i in range(0,len(trainTargets)):\n",
    "    if (trainTargets.iloc[i,0] in filter) == False:\n",
    "        trainTargets.iloc[i,0] = None\n",
    "trainTargets = trainTargets.dropna() # Deletes all rows with a None in it, i.e. entries not in the intersection.\n",
    "\n",
    "trainTargets.to_csv('trainTargetsFiltered.csv')\n",
    "\n",
    "for i in range(0,len(trainEvents)):\n",
    "    if (trainEvents.iloc[i,0] in filter) == False:\n",
    "        trainEvents.iloc[i,0] = None\n",
    "trainEvents = trainEvents.dropna() # Deletes all rows with a None in it, i.e. entries not in the intersection.\n",
    "\n",
    "trainEvents.to_csv('trainEventsFiltered.csv')\n",
    "\n",
    "trainFeatures0 = pd.read_csv('trainFeatures.csv', header = 0, index_col = 0)\n",
    "for i in range(0,len(trainFeatures0)):\n",
    "    if (trainFeatures0.iloc[i,0] in filter) == False:\n",
    "        trainFeatures0.iloc[i,0] = None\n",
    "trainFeatures0 = trainFeatures0.dropna() # Deletes all rows with a None in it, i.e. entries not in the intersection.\n",
    "\n",
    "trainFeatures0.to_csv('trainFeaturesFiltered.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56c653f2",
   "metadata": {},
   "source": [
    "Detect speech in each segment's label list (according to the set \"speech_events\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "72b7fcf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       video_id  time_stamp  speech_present\n",
      "10  --PJHxphWEs       30.00           False\n",
      "11  --PJHxphWEs       30.96           False\n",
      "12  --PJHxphWEs       31.92           False\n",
      "13  --PJHxphWEs       32.88           False\n",
      "14  --PJHxphWEs       33.84           False\n",
      "     segment_id  start_time_seconds  end_time_seconds      label\n",
      "24  O35jXasNYxc               0.000             0.381  /m/0dgw9r\n",
      "25  O35jXasNYxc               0.000            10.000  /m/093_4n\n",
      "26  O35jXasNYxc               0.733             1.578  /m/01b_21\n",
      "27  O35jXasNYxc               1.683             2.094  /m/01b_21\n",
      "28  O35jXasNYxc               2.191             2.565  /m/01b_21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jacob\\anaconda3\\envs\\hello-tf\\lib\\site-packages\\pandas\\core\\indexing.py:1743: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  isetter(ilocs[0], value)\n"
     ]
    }
   ],
   "source": [
    "trainTargets = pd.read_csv('../data/trainTargetsFiltered_unfinished.csv', header = 0, index_col = 0)\n",
    "trainEvents = pd.read_csv('../data/trainEventsFiltered.csv', header = 0, index_col = 0)\n",
    "print(trainTargets.head())\n",
    "print(trainEvents.head())\n",
    "\n",
    "# Respectively, speech, male speech, female speech, child speech, conversation, narration, babbling, synthetic speech.\n",
    "speech_events = set(['/m/09x0r', '/m/05zppz','/m/02zsn','/m/0ytgt','/m/01h8n0','/m/02qldy','/m/0261r1','/m/0brhx'])\n",
    "\n",
    "# Now check to see if each 0.96 second segment contains speech according to the trainEvents DF.\n",
    "'''This seems complicated at first glance, but the idea behind it is simple.\n",
    "Since each clip's events are grouped together in the trainEvents TSV, we just\n",
    "need to run a search ONCE for each clip label. Once we have it, we don't need\n",
    "to search again for the next entry's events unless its label is different.\n",
    "Sadly, the labels are NOT in alphabetical order, making an approach like this\n",
    "necessary.'''\n",
    "\n",
    "for i in range(0,len(trainTargets)):\n",
    "    if i == 0 or trainTargets.iloc[i,0] != trainTargets.iloc[i-1,0]:\n",
    "        clipset = trainEvents.loc[trainEvents['segment_id'] == trainTargets.iloc[i,0]]\n",
    "        clip_start_time = trainTargets.iloc[i,1]\n",
    "        clipset.loc[:,'start_time_seconds'] = clipset.loc[:,'start_time_seconds'] + clip_start_time\n",
    "        clipset.loc[:,'end_time_seconds'] = clipset.loc[:,'end_time_seconds'] + clip_start_time\n",
    "    for j in range(0,len(clipset)):\n",
    "        if clipset.iloc[j,3] in speech_events:\n",
    "            if trainTargets.iloc[i,1] <= clipset.iloc[j,1]:\n",
    "                if trainTargets.iloc[i,1] + 0.96 >= clipset.iloc[j,1]:\n",
    "                    trainTargets.iloc[i,2] = True\n",
    "            if trainTargets.iloc[i,1] >= trainEvents.iloc[j,1]:\n",
    "                if trainTargets.iloc[i,1] <= trainEvents.iloc[j,2]:\n",
    "                    trainTargets.iloc[i,2] = True\n",
    "\n",
    "trainTargets.to_csv('../data/trainTargets.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b72ac026",
   "metadata": {},
   "source": [
    "Repeat the entire process for the evaluation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "251cb92c",
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = [\"../data/audioset_v1_embeddings/eval/\" + i for i in get_filenames(\"../data/audioset_v1_embeddings/eval/\")]\n",
    "eval_dataset = tf.data.TFRecordDataset(filenames)\n",
    "\n",
    "# Make Pandas DataFrame out of the training set records.\n",
    "col = ['video_id', 'time_stamp'] + [str(k) for k in range(0,128)]\n",
    "\n",
    "placeholder_array = np.array(col)\n",
    "\n",
    "for raw_record in eval_dataset:\n",
    "    example = tf.train.SequenceExample()\n",
    "    example.ParseFromString(raw_record.numpy())\n",
    "    for i in range(0,len(example.feature_lists.feature_list['audio_embedding'].feature)):\n",
    "        vID = example.context.feature['video_id'].bytes_list.value[0]\n",
    "        time = example.context.feature['start_time_seconds'].float_list.value[0] + 0.96*i\n",
    "        placeholder_array = np.vstack((placeholder_array, np.array([vID, time] + list(example.feature_lists.feature_list['audio_embedding'].feature[0].bytes_list.value[0]))))\n",
    "\n",
    "evalFeatures = pd.DataFrame(np.delete(placeholder_array, 0, 0), columns = col)\n",
    "\n",
    "evalFeatures.to_csv('../data/evalFeatures.csv')\n",
    "\n",
    "# Make a Pandas DataFrame of all instances of speech present.\n",
    "evalEvents = pd.read_csv(\"../data/audioset_eval_strong_framed_posneg.tsv\", sep=\"\\t\")\n",
    "\n",
    "''' Have to make the labels match the feature set,\n",
    "    and these labels have a \"_\" followed by trailing digits.'''\n",
    "evalEvents.iloc[:,0] = evalEvents.iloc[:,0].str.rstrip(\"0123456789\")\n",
    "evalEvents.iloc[:,0] = evalEvents.iloc[:,0].str.rstrip(\"_\")\n",
    "\n",
    "filter = set(evalFeatures.iloc[:,0]).intersection(set(evalEvents.iloc[:,0]))\n",
    "\n",
    "for i in range(0,len(evalFeatures)):\n",
    "    if (evalFeatures.iloc[i,0] in filter) == False:\n",
    "        evalFeatures.iloc[i,0] = None\n",
    "evalFeatures = evalFeatures.dropna() # Deletes all rows with a None in it, i.e. entries not in the intersection.\n",
    "evalFeatures.to_csv('../data/evalFeaturesFiltered.csv')\n",
    "\n",
    "for i in range(0,len(evalEvents)):\n",
    "    if (evalEvents.iloc[i,0] in filter) == False:\n",
    "        evalEvents.iloc[i,0] = None\n",
    "evalEvents = evalEvents.dropna() # Deletes all rows with a None in it, i.e. entries not in the intersection.\n",
    "evalEvents.to_csv('../data/evalEventsFiltered.csv')\n",
    "\n",
    "# Finally, make a Pandas DF for the target: whether or not speech is present in each 0.96 second chunk.\n",
    "evalTargets = pd.read_csv('../data/evalFeaturesFiltered.csv', header = 0, index_col = 0).iloc[:,0:2]\n",
    "evalTargets['speech_present'] = False # By default.\n",
    "\n",
    "# Respectively, speech, male speech, female speech, child speech, conversation, narration, babbling, synthetic speech.\n",
    "speech_events = set(['/m/09x0r', '/m/05zppz','/m/02zsn','/m/0ytgt','/m/01h8n0','/m/02qldy','/m/0261r1','/m/0brhx'])\n",
    "\n",
    "# Now check to see if each 0.96 second segment contains speech according to the evalEvents DF.\n",
    "'''This seems complicated at first glance, but the idea behind it is simple.\n",
    "Since each clip's events are grouped together in the trainEvents TSV, we just\n",
    "need to run a search ONCE for each clip label. Once we have it, we don't need\n",
    "to search again for the next entry's events unless its label is different.\n",
    "Sadly, the labels are NOT in alphabetical order, making an approach like this\n",
    "necessary.'''\n",
    "\n",
    "for i in range(0,len(evalTargets)):\n",
    "    if i == 0 or evalTargets.iloc[i,0] != evalTargets.iloc[i-1,0]:\n",
    "        clipset = evalEvents.loc[evalEvents['segment_id'] == evalTargets.iloc[i,0]]\n",
    "        clip_start_time = evalTargets.iloc[i,1]\n",
    "        clipset.loc[:,'start_time_seconds'] = clipset.loc[:,'start_time_seconds'] + clip_start_time\n",
    "        clipset.loc[:,'end_time_seconds'] = clipset.loc[:,'end_time_seconds'] + clip_start_time\n",
    "    for j in range(0,len(clipset)):\n",
    "        if clipset.iloc[j,3] in speech_events and clipset.iloc[j,4] == 'PRESENT':\n",
    "            if evalTargets.iloc[i,1] == clipset.iloc[j,1]:\n",
    "                evalTargets.iloc[i,2] = True\n",
    "\n",
    "evalTargets.to_csv('../data/evalTargetsFiltered.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bbb9d40",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
