{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "454637ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.models import Sequential, model_from_json\n",
    "from tensorflow.keras import layers\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15b5ae95",
   "metadata": {},
   "source": [
    "Load the TFRecord file for the WAV demonstration sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad34631f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[102.,  76., 166., ..., 139., 179., 222.],\n",
       "       [ 72.,  81., 155., ...,  49., 136., 192.],\n",
       "       [ 66.,  70., 156., ...,  22., 219., 252.],\n",
       "       ...,\n",
       "       [ 27.,  86., 185., ...,  98., 234., 105.],\n",
       "       [ 26.,  67., 175., ...,  75., 217., 151.],\n",
       "       [ 26.,  78., 168., ...,   0., 255., 102.]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filenames = [\"../data/newtfrecordiguess.tfr\"]\n",
    "raw_dataset = tf.data.TFRecordDataset(filenames)\n",
    "\n",
    "# This is just so np.vstack has another row to stack with.\n",
    "placeholder_array = np.array([str(k) for k in range(0,128)])\n",
    "\n",
    "# Extract the 128-dimensional vectors from the TFRecord file.\n",
    "for raw_record in raw_dataset:\n",
    "    sample = tf.train.SequenceExample()\n",
    "    sample.ParseFromString(raw_record.numpy())\n",
    "    for i in range(0,len(sample.feature_lists.feature_list['audio_embedding'].feature)):\n",
    "        placeholder_array = np.vstack((placeholder_array, np.array(list(sample.feature_lists.feature_list['audio_embedding'].feature[i].bytes_list.value[0]))))\n",
    "\n",
    "features = np.delete(placeholder_array, 0, 0).astype(float)\n",
    "print(len(features))\n",
    "features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3a1246f",
   "metadata": {},
   "source": [
    "Load the trained model and use it to predict the presence of speech in the sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "23e306f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.]], dtype=float32)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_file = open('../models/model.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "model = model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "model.load_weights('../models/model.h5')\n",
    "model.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "print(\"Loaded model from disk\")\n",
    "\n",
    "predictions = np.round(model.predict(features))\n",
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3947211f",
   "metadata": {},
   "source": [
    "Finally, make the 1D heatmap visualizing the predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dac57ae4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 16.0)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x72 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.rcParams['figure.figsize']= 5,1\n",
    "\n",
    "x = np.arange(0,len(features))\n",
    "y = predictions\n",
    "\n",
    "fig, (ax) = plt.subplots(nrows=1)\n",
    "extent = [0, len(features), 0., 1.]\n",
    "ax.imshow(y[np.newaxis,:], cmap='plasma', aspect='auto', extent=extent)\n",
    "ax.set_yticks([])\n",
    "ax.set_xlim(extent[0], extent[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a23c2510",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
