{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "454637ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.models import Sequential, model_from_json\n",
    "from tensorflow.keras import layers\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15b5ae95",
   "metadata": {},
   "source": [
    "Load the TFRecord file for the WAV demonstration sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad34631f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 85., 131., 153., ...,  38.,   0., 255.],\n",
       "       [ 84.,  81., 162., ...,  70.,  60., 255.],\n",
       "       [ 47., 117., 125., ...,  68., 233.,  31.],\n",
       "       ...,\n",
       "       [ 75., 107., 164., ...,   0.,  50., 255.],\n",
       "       [ 57.,  83., 153., ...,   0.,  17.,  87.],\n",
       "       [ 55.,  70., 155., ..., 144.,  87.,  28.]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filenames = [\"../data/featuresFromSample.tfr\"]\n",
    "raw_dataset = tf.data.TFRecordDataset(filenames)\n",
    "\n",
    "# This is just so np.vstack has another row to stack with.\n",
    "placeholder_array = np.array([str(k) for k in range(0,128)])\n",
    "\n",
    "# Extract the 128-dimensional vectors from the TFRecord file.\n",
    "for raw_record in raw_dataset:\n",
    "    sample = tf.train.SequenceExample()\n",
    "    sample.ParseFromString(raw_record.numpy())\n",
    "    for i in range(0,len(sample.feature_lists.feature_list['audio_embedding'].feature)):\n",
    "        placeholder_array = np.vstack((placeholder_array, np.array(list(sample.feature_lists.feature_list['audio_embedding'].feature[i].bytes_list.value[0]))))\n",
    "\n",
    "features = np.delete(placeholder_array, 0, 0).astype(float)\n",
    "print(len(features))\n",
    "features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3a1246f",
   "metadata": {},
   "source": [
    "Load the trained model and use it to predict the presence of speech in the sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "23e306f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.]], dtype=float32)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_file = open('../models/model.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "model = model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "model.load_weights('../models/model.h5')\n",
    "model.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "print(\"Loaded model from disk\")\n",
    "\n",
    "predictions = np.round(model.predict(features))\n",
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3947211f",
   "metadata": {},
   "source": [
    "Finally, make the 1D heatmap visualizing the predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dac57ae4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 12.0)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x72 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.rcParams['figure.figsize']= 5,1\n",
    "\n",
    "x = np.arange(0,len(features))\n",
    "y = predictions\n",
    "\n",
    "fig, (ax) = plt.subplots(nrows=1)\n",
    "extent = [0, len(features), 0., 1.]\n",
    "ax.imshow(y[np.newaxis,:], cmap='plasma', aspect='auto', extent=extent)\n",
    "ax.set_yticks([])\n",
    "ax.set_xlim(extent[0], extent[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a23c2510",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
