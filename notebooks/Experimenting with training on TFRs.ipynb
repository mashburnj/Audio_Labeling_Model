{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c2f5dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# Taken from the EDA notebook\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "def get_filenames(mypath):\n",
    "    return [f for f in listdir(mypath) if isfile(join(mypath, f))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "93737214",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "(0, 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\envs\\hello-tf\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2897\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2898\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2899\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: (0, 0)",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-5acfed5e5b6c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     23\u001b[0m     ''' Have to make the labels match the feature set,\n\u001b[0;32m     24\u001b[0m         and these labels have a \"_\" followed by trailing digits.'''\n\u001b[1;32m---> 25\u001b[1;33m     \u001b[0mtrainEvents\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrainEvents\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrstrip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"0123456789\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m     \u001b[0mtrainEvents\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrainEvents\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrstrip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"_\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtrainEvents\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mspeech_events\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\hello-tf\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2904\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2905\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2906\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2907\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2908\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\hello-tf\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2898\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2899\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2900\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2901\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2902\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtolerance\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: (0, 0)"
     ]
    }
   ],
   "source": [
    "filenames = [\"../data/audioset_v1_embeddings/bal_train/\" + i for i in get_filenames(\"../data/audioset_v1_embeddings/bal_train/\")]\n",
    "train_dataset = tf.data.TFRecordDataset(filenames)\n",
    "\n",
    "# Make Pandas DataFrame out of the training set records.\n",
    "trainFeatures = pd.DataFrame(columns = ['video_id', 'time_stamp'].append(range(0,127)))\n",
    "for raw_record in train_dataset:\n",
    "    example = tf.train.SequenceExample()\n",
    "    example.ParseFromString(raw_record.numpy())\n",
    "    for i in range(0,len(example.feature_lists.feature_list['audio_embedding'].feature)):\n",
    "        vID = example.context.feature['video_id'].bytes_list.value[0]\n",
    "        time = example.context.feature['start_time_seconds'].float_list.value[0] + 0.96*i\n",
    "        newEntry = pd.DataFrame([vID, time].append(list(example.feature_lists.feature_list['audio_embedding'].feature[i].bytes_list.value[0])), columns = ['video_id', 'time_stamp'].append(range(0,127)))\n",
    "        trainFeatures = pd.concat([trainFeatures, newEntry])\n",
    "\n",
    "trainFeatures.to_csv('trainFeatures.csv')\n",
    "\n",
    "# Respectively, speech, male speech, female speech, child speech, conversation, and narration.\n",
    "speech_events = set(['/m/09x0r', '/m/05zppz','/m/02zsn','/m/0ytgt','/m/01h8n0','/m/02qldy'])\n",
    "\n",
    "# Make a Pandas DataFrame of all instances of speech present.\n",
    "trainEvents = pd.read_csv(\"../data/audioset_train_strong.tsv\", sep=\"\\t\")\n",
    "for i in range(0,len(trainEvents)):\n",
    "    ''' Have to make the labels match the feature set,\n",
    "        and these labels have a \"_\" followed by trailing digits.'''\n",
    "    trainEvents.iloc[i,0] = trainEvents.iloc[i,0].rstrip(\"0123456789\")\n",
    "    trainEvents.iloc[i,0] = trainEvents.iloc[i,0].rstrip(\"_\")\n",
    "    if (trainEvents.iloc[i,3] in speech_events) == False:\n",
    "        trainEvents.iloc[i,3] = None\n",
    "trainEvents = trainEvents.dropna() # Deletes all rows with a None in it, i.e. entries that have no speech.\n",
    "\n",
    "# Finally, make a Pandas DF for the target: whether or not speech is present in each 0.96 second chunk.\n",
    "trainTargets = trainFeatures[:,:'time_stamp']\n",
    "del TrainFeatures # For RAM's sake. We've already saved this to a CSV.\n",
    "\n",
    "trainTargets['speech_present'] = False # By default.\n",
    "\n",
    "# Now check to see if each 0.96 second segment contains speech according to the trainEvents DF.\n",
    "'''This seems complicated at first glance, but the idea behind it is simple.\n",
    "Since each clip's events are grouped together in the trainEvents TSV, we just\n",
    "need to run a search ONCE for each clip label. Once we have it, we don't need\n",
    "to search again for the next entry's events unless its label is different.\n",
    "Sadly, the labels are NOT in alphabetical order, making an approach like this\n",
    "necessary.'''\n",
    "\n",
    "first_label_match = 0\n",
    "for i in range(0,len(trainTargets)):\n",
    "    if first_label_match == 0:\n",
    "        while (trainTargets.iloc[i,0] != trainEvents.iloc[first_label_match,0]):\n",
    "            first_label_match += 1\n",
    "    offset = 0\n",
    "    while (trainTargets.iloc[i,0] == trainEvents.iloc[first_label_match + offset,0]):\n",
    "        if trainTargets.iloc[i,1] <= trainEvents.iloc[first_label_match + offset,1]:\n",
    "            if trainTargets.iloc[i,1] + 0.96 >= trainEvents.iloc[first_label_match + offset,1]:\n",
    "                trainTargets.iloc[i,2] = True\n",
    "        if trainTargets.iloc[i,1] >= trainEvents.iloc[first_label_match + offset,1]:\n",
    "            if trainTargets.iloc[i,1] <= trainEvents.iloc[first_label_match + offset,2]:\n",
    "                trainTargets.iloc[i,2] = True\n",
    "        offset += 1\n",
    "    if i != len(trainTargets) - 1:\n",
    "        if trainTargets.iloc[i,0] != trainTargets.iloc[i+1,0]:\n",
    "            first_label_match = 0\n",
    "\n",
    "trainTargets.to_csv('trainTargets.csv')\n",
    "\n",
    "# When done, we can drop the labels and time indices, since the orders are the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20bd4d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do the same for the eval DS...\n",
    "filenames = [\"../data/audioset_v1_embeddings/eval/\" + i for i in get_filenames(\"../data/audioset_v1_embeddings/bal_train/\")]\n",
    "eval_dataset = tf.data.TFRecordDataset(filenames)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7644c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This was copy-pasted from my old personal project.\n",
    "# Some of the layers are not applicable (normalization),\n",
    "# and some layers (input, reshape, resizing, and dense) need to be resized.\n",
    "# shape = (,), (leftover from the input layer)\n",
    "\n",
    "model = Sequential([\n",
    "    layers.Input(ragged=True),\n",
    "    layers.Conv2D(4, 3, activation='relu'),\n",
    "    layers.MaxPooling2D(),\n",
    "    layers.Conv2D(4, 3, activation='relu'),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(200, activation='relu'),\n",
    "    layers.Dense(160, activation='relu'),\n",
    "    layers.Dense(120, activation='relu'),\n",
    "    layers.Dense(80, activation='relu'),\n",
    "    layers.Dense(37, activation='relu')\n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b9a3808",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = 'mean_squared_error', optimizer = 'adam', metrics = ['mean_squared_error'])\n",
    "model.fit(trainFeatures,trainTargets,epochs = 100, batch_size = 4)\n",
    "if save_to_disk:\n",
    "    # Saving model to JSON and weights to H5.\n",
    "    os.chdir('..')\n",
    "    os.chdir('./models/')\n",
    "    model_json = model.to_json()\n",
    "    with open(\"model.json\", \"w\") as json_file:\n",
    "        json_file.write(model_json)\n",
    "    model.save_weights(\"model.h5\")\n",
    "    print(\"Saved model to disk\")\n",
    "loss  = model.evaluate(ValFeatures, ValTargets)\n",
    "print('Loss on Validation Set: ', loss)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
